{"name": "i shopee text prep fe image augmentation ", "full_name": " h1 Data Preprocessing h1 1 Introduction h3 Goal h3 Challenges h3 Libraries W B h1 2 Data Images h2 2 1 Duplicated Images h3 Clean Duplicates Function h2 2 2 Label Group h2 2 3 Image Augmentation h1 3 Data Texts h2 3 1 Text Preprocessing step by step h3 Text Preprocessing Function h2 3 2 Text Features Extraction h3 Explore the Features h2 3 3 Text Exploration h3 Wordcloud h2 3 4 Create Text Embeddings h1 4 Final Preprocessing Function h3 Training Submission Notebook here II Shopee Model Training with Pytorch x RAPIDS h1 Specs on how I prepped explored h3 on my local machine ", "stargazers_count": 0, "forks_count": 0, "description": " img src https i imgur com gODdzoI png center h1 Data Preprocessing h1 center 1 Introduction Goal Building a model that can identify which images contain the same product s Challenges Finding near duplicates of the product and NOT the image Erasing the impact of the background the area surrounding the product Using the description of the image or the title Libraries W B Create an account on https wandb ai Input your personal key of the project mine will be secret as it is confidential You can find my project in the W B Dashboard by clicking here https wandb ai andrada shopee kaggle workspace user andrada 2 Data Images train train images the product photos 32 400 files train csv the corresponding metadata each product is assigned a label group that marks the images with identical products test test images the product photos to be predicted 70 000 hidden files only 3 showing test csv the corresponding metadata 2 1 Duplicated Images There are 1 246 images that have 2 or more apparitions The title differs for most of them The label group is usually the same but there are a few cases where it differs as well You can check the plot in the W B Project img src https i imgur com bmAG5Zh png width 650 I also wanted to look at how these images with same image name look and what trully differentiates them The description usually reffers to the same object but the wording is different The Group ID can sometimes be different although the image is exactly the same this means that the text description is the one that is indicating the category in these instances Note If you re using cv2 to visualize the images note that they will be displayed in the BGR colorspace blue green red order for some reason this is the default of this library To correct that you can use cv2 cvtColor to display them in the RGB colorspace Clean Duplicates Function Hence we ll clean these duplicates by selecting only the first appearence for each 2 2 Label Group Note If there are 2 or more images with the same label group it means that these have been already mapped as being identical And this is the plot in the W B Project img src https i imgur com eOHWhjQ png width 650 Let s also observe the images within some of the groups There is definitely a resemblance between products for the human eye For some groups however the overall structure of the images is very different 2 3 Image Augmentation Another aspect I wanted to explore was the different kinds of augmentation that might be performed on the images so that the model can better pick up unique patterns Note From my research the best performing augmentations for this type of problem were flips vertical flip horizontal flip etc crops center crop random crop etc and rotations as they display the product in different positions without changing its color or texture attributes Below you can see an example of an image and 11 different applied augmentations You can find the albumentations documentation here https vfdev 5 albumentations readthedocs io en docs pytorch fix api augmentations html 3 Data Texts 3 1 Text Preprocessing step by step Before analyzing the text we ll have to prepare it a little bit so the insights we ll gain afterwards will be as accurate as possible Disclaimer I chose NOT to remove numbers as they might be very important when it comes to how many ml or how many pieces are in the package of a product I am thinking numbers might actually give a huge insight for our prediction Text Preprocessing Function Note This function takes 30 mins in the Kaggle environment But Maxim Vlah https www kaggle com maximvlah came in the comments with the amazing library called pandarallel which enables parallelisation when applying apply function in pandas You can check the GitHub repo here https github com nalepae pandarallel Now the same function takes about 8 9 minutes Check out preprocessing methodology below 3 2 Text Features Extraction Another method was to extract features from the title column in an attempt to feed into the final model more useful information You can check out this article https towardsdatascience com textfeatures library for extracting basic features from text data f98ba90e3932 for more about the textfeatures library The extractions were word count counts how many words are in a sentence char count counts how many characters are in a sentence avg word length counts what s the average word length in a sentence stopwords count counts how many stopwords are in a sentence numerics count counts how many numbers are in a sentence Explore the Features Within out title variable the texts are usually 10 words long with 50 characters and containing 1 to 2 numerics 3 3 Text Exploration Now let s look at the newly created title prep Create Custom Plot for W B Let s also explore the pos Part of Speech column WRB wh adverb how WP wh pronoun who VBZ verb present tense with 3rd person singular bases VBP verb present tense not 3rd person singular wrap RP particle about You can find full list here https www guru99 com pos tagging chunking nltk html text POS 20Tagging 20in 20NLTK 20is each 20word 20of 20the 20sentence Create Custom Plot for W B Wordcloud 3 4 Create Text Embeddings Let s append now the TF IDF CountVectorizer embeddings explored above to our training dataframe Note We ll end up with 26 705 columns instead of the 12 we are working with now or 5 in the original training dataset 4 Final Preprocessing Function We ll need the functions we created in this notebook to preprocess the test dataframe as well before applying the ML model Hence is best to create a preprocess df function that contains the necessary metadata process pipeline Remember We ll use an Unsupervised ML Technique to make our prediction for this competition Hence all methodologies we ll apply for the CV score we ll also need to use for the submission notebook More on that in my next notebook https www kaggle com andradaolteanu ii shopee model training with pytorch x rapids Training Submission Notebook here II Shopee Model Training with Pytorch x RAPIDS https www kaggle com andradaolteanu ii shopee model training with pytorch x rapids img src https i imgur com cUQXtS7 png Specs on how I prepped explored on my local machine Z8 G4 Workstation 2 CPUs 96GB Memory NVIDIA Quadro RTX 8000 RAPIDS version 0 17  Libraries Enable progress tracking Environment check Secrets Color scheme Read in data Log into W B Get the count of apparitions per image Make a custom plot to save into W B Prepare data Create Table log the plot Read in the image corresponding metadata Plot image Example 1 Example 2 Example 3 Clean duplicates Get count of values on each group Print info Make a custom plot to save into W B Prepare data Create Table log the plot Retrieve a sample of 6 images from this group Plot Example 1 Example 2 Example 3 Read in original image Transformations Apply transformations Plot END of EXPERIMENT Original Convert to lower case Remove punctuation Remove whitespaces Tokenize words Remove stopwords Lemmatization Part of speech tagging ner text ne chunk pos tag lemmatized text print NER ner text Lower Case Remove Punctuation Remove whitespaces Tokenize Remove stopwords Lemmatization Part of speech tagging Process preprocessed title Add part of speech Read in prepped data Save also as artifact Extract Features Plot Another W B Experiment Get bag of words from the title Plot Make a custom plot to save into W B Prepare data Create Table log the plot Get bag of words from pos column Plot Make a custom plot to save into W B Prepare data Create Table log the plot Get all titles Wordcloud stopwords wc update yes Plot END of EXPERIMENT Vectorizer functions don t support NAs so we need to remove if any title vectorizer Create dataframe pos vectorizer Create dataframe Concatenate all data together Get title and pos embeddings Let s also save it to W B project Clean duplicates Preprocess title get POS Extract title features Get embeddings from title and pos Test the preprocess df function ", "id": "andradaolteanu/i-shopee-text-prep-fe-image-augmentation", "size": "6950", "language": "python", "html_url": "https://www.kaggle.com/code/andradaolteanu/i-shopee-text-prep-fe-image-augmentation", "git_url": "https://www.kaggle.com/code/andradaolteanu/i-shopee-text-prep-fe-image-augmentation"}