{"name": "synthesisdefensivebehavior ", "full_name": " h1 0 Introduction h3 Case No 1 h1 1 Data h1 3 Model h1 3 Results h2 Visual Investigation h2 How is Denver doing in our first example AND how are our policies doing h1 4 Summary and Future Outlook h1 1 Links and Resources ", "stargazers_count": 0, "forks_count": 0, "description": " 0 Introduction in this report we present our analysis for the NFL Big Data Bowl Competition One of the most interesting questions posed by the NFL was How does a defense react to certain types of offensive plays In this report we want to give a tool that can estimate how defense is reacting to specific offensive plays Therefore We leveraged immitation learning to simulate defensive team behavior Paper https arxiv org abs 1703 03121 Analysed player movement of the simulation Included Meta data of the game state to change behavior Case No 1 Imagine you are the coach of the Denver Broncos your team is a few yards away of scoring a touchdown and you and your team are of course interested how the opposing teams defense is going to behave So you basically scatched the offensive play and you know how the defensive team is going to line up This could look like After scatching your offensive play you basically need your defensive coach who tells you how he would defend it And he would scribble something on the board which helps to adapt your offensive play This is how the players actually moved before the pass was thrown Would you guessed the movement in a similar faishon Or your defensive coach We present the Average Defense Behavior Prediction Network which is able to simulate the average defensive team behavior 1 Data For training the model we used 14 weeks of the regular season game data 2 weeks for evaluation and one week for testing the input data consists of all the plays conducted with 13 tracked players and the football For each player we had the features absolute position relative position to the ball velocity in x and y coordinates for each timestep we hand the model the information of features of each player down yards left for the offensive team to get the next touchdown We do NOT use the orientation of the players as it is hard to predict the upper body orientation as it is somewhat uncorrelated to the movement and have not really improved the prediction as it also needed to be estimated All the presented features resulted in a feature vector length of 82 78 of those entries are features correlated to specific players 2 are the ball absolute position and the last 2 features are the meta data The players are sorted according to their team and position first we included the features of the defensive team sorted after following positions 1 CB 2 SS 3 FS 4 S 5 DB 6 DE The offensive team is sorted as follows 1 WR 2 RB 3 TE 4 FB 5 QB As the most positions are double staffed we filled up the positions in the appearing order So if the defensive team looks i e somewhat 2CB 2S 2DE 1DB the positions where filled as CB CB S S DB DE DE 3 Model The problem of synthesising the defensive team can be formulated as predicting the next position of a set of previous positions of a single agent and collaborators Therefore our dataset consist of a sequence of demonstrations of the players positions and its meta data described in 2 Data We assume that every single agents identity does not change over a single demonstration this means that the role does NOT change dynamically within the same sequence this reduces our prediciton problem as we do not need to match the agents with their corresponding models in training This problem is described in Ross et al https arxiv org abs 1011 0686 and is a subarea of reinforcement learning Policy Learning The problem is abstracted to learning the action a k of agent k corresponding to policy pi k as pi k s k a k where s k describes the state of agent k This decentralized setting can be decomposed into minimizing mathcal L imitation sum k mathrm E s l pi k s k where l determines the loss function In our case its the L1 Loss To prevent the model to deveate to much from the training distribution we use DAgger to train the estimator DAgger is coded as 1 Predict next action with estimator from the baseline dataset 2 Update trainig Data with prediction from 1 and create an updated dataset mathcal D star 3 Train Estimator with dataset mathcal D star The main idea is to use the learned policy s own prediction in the construction of subsequent states thus simulating the test time performance during training Le et al https arxiv org abs 1703 03121 As estimator we use LSTM Networks as they are especially matching the requirements of learning sequential information The training data are all the plays from ball snap until the bitter end We use a sequence length of 15 frames and train with sequence overlap of 5 frames Overall we train with 62 000 training samples a 15 frame sequences with 82 features The validation set contains 8 000 samples The test set is the last week of the regualar season 3 Results Due to a lag of time we did not train our networks till the validation set did not further improve or build ensamble models those will be found in the github repository belonging to this report The models discussed here hat a mean training error of 1 2m were not pretrained with the pure immitation dataset and were not fully converged at the time of submitting the report Let s compare the estimated trajectories from ball snap to Quarterback forward pass with the true trajectories to get a feeling for the accuracy of the predictions Visual Investigation Let s investigate the play where Keenum is passing deep left to Sutton and gained 25 yards Above we can see the play from ball snap to forward pass Denver is shown in yellow while the LA Chargers are defending in blue Below we can see how our algorithm is predicting the defensive sequence Seems like our model is a little bit stuttery and a few inches of yet it already captures the movement of players and their running destination How is Denver doing in our first example AND how are our policies doing Well to answer this quesition just have a look into our models prediction for the respective play The model seems to be a little bit more defensive then the players actually would be but it predicts the movement of the players for this simple formation well while in the previous more complicated play the defensive positions were predicted worse 4 Summary and Future Outlook We trained a neural network witch is able to capture general movement of players Theoretically it is possible to scatch offensive plays and let the model generate the defensive player movement The models are not fully converged and we assume that after a few more hours of training we are going to have a more precise model without any wiggeling With the current model it is not really useful to change meta data as number of down yards to go or player alignment as the details of the predicted position would vanish in the noise of the model yet I am confident future models in the Repository https github com marcimarc1 NFL2021 are going to be able to capture small differences in defender movement 1 Links and Resources Repo https github com marcimarc1 NFL2021 DAgger https arxiv org abs 1011 0686 Immitation Learning https arxiv org abs 1703 03121  np expand dims trajectory teamInfo to numpy 1 Endzones fontname Arial fontname Arial 308 28 11 317 28 11 9 30 13 308 28 11 317 28 11 9 30 13 np expand dims trajectory teamInfo to numpy 1 ", "id": "marcimarc/synthesisdefensivebehavior", "size": "7322", "language": "python", "html_url": "https://www.kaggle.com/code/marcimarc/synthesisdefensivebehavior", "git_url": "https://www.kaggle.com/code/marcimarc/synthesisdefensivebehavior"}