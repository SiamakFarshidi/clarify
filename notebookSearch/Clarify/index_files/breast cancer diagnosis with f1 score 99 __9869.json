{"name": "breast cancer diagnosis with f1 score 99 ", "full_name": " h1 Breast Cancer h2 A Problem Understanding h2 B Data Understanding h4 1 Data Description h4 2 Load The Data h4 3 Data Types h1 C Data Exploration h1 D Data Preprocessing h4 1 Data Selection h4 2 Preprocess Data h4 3 Data Transformation h1 E Data Modelling h4 1 Random Forest h4 2 KNN h4 3 SVM h1 F Evaluation ", "stargazers_count": 0, "forks_count": 0, "description": " Breast Cancer A Problem Understanding Despite a great deal of public awareness and scientific research breast cancer continues to be the most common cancer and the second largest cause of cancer deaths among women Approximately 12 of U S women will be diagnosed with breast cancer and 3 5 will die of it The annual mortality rate of approximately 28 deaths per 100 000 women has remained nearly constant over the past 20 years A breast cancer victim s chances for long term survival are improved by early detection of the disease and early detection is in turn enhanced by an accurate diagnosis After the diagnosis for each patient with breast cancer we classify the severity of cancers as malignant or benign in order to give them special treatments B Data Understanding First a sample of fluid is taken from the patient s breast This outpatient procedure involves using a small gauge needle to take the fluid known as a fine needle aspirate FNA directly from a breast lump or mass the lump having been previously detected by self examination and or mammoaphy The fluid from the FNA is placed on a glass slide and stained to highlight the nuclei of the constituent cells An image from the FNA is transferred to a workstation by a video camera mounted on a microscope Xcyt uses a curve fitting program to determine the exact boundaries of the nuclei The boundaries are initialized by an operator using a mouse pointer For a typical image containing between 10 and 40 nuclei the image analysis process takes approximately two to five minutes Ten features are computed for each nucleus area radius perimeter symmetry number and size of concavities fractal dimension of the boundary compactness smootimess local variation of radial seg ments and texture variance of gray levels inside the boundary The mean value extreme value i e largest or worst value biggest size most irregular shape and standard error of each of these cellular features are com puted for each image resulting in a total of 30 real valued features 1 Data Description data csv 1 ID number 2 Diagnosis M malignant B benign 3 Ten real valued features are computed for each cell nucleus radius mean of distances from center to points on the perimeter texture standard deviation of gray scale values perimeter area smoothness local variation in radius lengths compactness perimeter 2 area 1 0 concavity severity of concave portions of the contour concave points number of concave portions of the contour symmetry fractal dimension coastline approximation 1 Note Mean Etandard Error SE and Worst mean of the three largest values of these features are obtained from each image resulting in 30 features For example the third column is Mean Radius column 13 is Radius SE column 23 is Worst Radius All feature values are stored with four significant numbers 2 Load The Data 3 Data Types C Data Exploration On the data exploration we will see the distribution of each variable using a histogram In the histogram the horizontal axis is the data of the feature while the vertical axis is the frequency of occurrence The correlation test is used to evaluate the relationship between two numerical variables If two variables have a correlation coefficient then the two variables are numerical variables while the remainder are categorical variables Before go to correlation test we need to change the target of classification in the column of diagnosis to be numerical So we can also include the target to the correlation test because the correlation test can process only numerical data It is also important to binarized our target because it is need to convert to 0 and 1 to calculate F1 score of our model evaluation We also consider to remove unnecessary data that is clearly not required For example the patient ID and other blank features This is helpful to speed up our correlation test There are 31 features now including the target Next let s explore all variables using Pandas Proiling Report From the histograms below we can see the distributions are normal D Data Preprocessing 1 Data Selection Now we need to select the data based on the question that we want to address which is classification of the cancer Even though the available data are seems to be relevant we need to conduct the correlation test to make sure we used the features that are must be included The available data can includes independent variables and dependent variables What we need is to ensure the inputs include all independent varibales and each feature doesn t make a high correlation with the target or with other input s we can identify them by evaluating through correlation test If the data are highly correlated we then exlude it From the Pandas Profiling thare are 14 warnings 4 are due to zero values In this case because the data are obtained using real image we assume zero values are possible and not human error so we can t exclude that From the above warning we can see that there are 10 warning regarding the correlation of the features we can group them as 2 groups of correlation test Group 1 Features in Radius Perimeter and Area Take a look at the pandas profile report area mean is highly correlated with perimeter mean \u03c1 0 98651 Rejected area se is highly correlated with perimeter se \u03c1 0 93766 Rejected area worst is highly correlated with perimeter worst \u03c1 0 97758 Rejected perimeter mean is highly correlated with radius mean \u03c1 0 99786 Rejected perimeter se is highly correlated with radius se \u03c1 0 97279 Rejected perimeter worst is highly correlated with radius worst \u03c1 0 99371 Rejected radius worst is highly correlated with area mean \u03c1 0 96275 Rejected First we will choose one out of three variables that are higly correlated From radius mean perimeter mean and area mean we choose radius mean From radius se perimeter se and area se we choose radius se From radius worst perimeter worst and area worst we choose radius worst Second due to the high correlation of the radius features radius mean and radius worst we need to choose one let s take the radius mean At this step we keep 2 variables radius mean and radius se and will exclude 7 other variables in group 1 perimeter mean area mean perimeter se area se radius worst perimeter worst area worst Group 2 Features in concave points texture and concavity Look at the pandas profile report we can witness concave points mean is highly correlated with concavity mean \u03c1 0 92139 Rejected concave points worst is highly correlated with concave points mean \u03c1 0 91016 Rejected texture worst is highly correlated with texture mean \u03c1 0 91204 Rejected As on the previous test we need to keep some features and remove the other features that are unnecessary From concave points mean concavity mean and concave points worst we choose concave points mean From texture mean and texture worse we choose texture mean At this step we keep variables concave points mean and texture mean and will exclude 3 other variables in group 2 concavity mean concave points worst and texture worse 2 Preprocess Data After we know what features to be excluded let s make the sample data for analysis or the data that we want to work with 3 Data Transformation We need to check the boundaries minimum and maximum values of each features It is better to scale the numeric data because every feature has different scale E Data Modelling Let s prapare our input and output using tran test split before we create models We create 3 basic models and then optimze each models using Hyperparameter Search technique The model we used are 1 Random Forest 2 K Nearest Neighbours 3 Support Vector Machine SVM 1 Random Forest 2 KNN 3 SVM For the above confusion matrix we can see that the false positive 0 and the false negative 1 Let me remind you what does it mean False positives FP We predicted yes but they don t actually have the malignant cancer False negatives FN We predicted no but they actually do have the malignant cancer FP is the most important indicator To illustrate if there is a value in FP it means that the patient with benign cancer predicted as malignant cancer It is very dangerous because the patient will have the serious treatment consume a high dose drug category or have a serious surgery that is actually not appropriate for such patient If the cancer is identified as malignant there is a sort amount of time or even no time to re evaluate the patient and the wrong treatment will be taken by the doctor and make the patient in danger In contrast a value in FN is the number of malignant patient who are predicted as benign There is a time to re assess the patient in order to provide better treatment Clearly this not severe as the opposite situation Because the FP is zero and NP is very small 1 The predictive model using SVM does very well F Evaluation Overall the model perform well to predict the class of cancer with F1 score 94 even not using hyperparameter optimization F1 score of Random Forest model 94 7 F1 score of KNN model 97 0 F1 score of SVM model 99 3 To increase the F1 score we have applied hyperparameter tuning using RandomizedSearch and obtain F1 score of Optmized Random Forest model 94 9 F1 score of Optmized KNN model 97 7 F1 score of Optmized SVM model 99 3 We can conclude that SVM is the best model to classify the breast cancer with the optimum F1 score of 99 3 ", "id": "busthon/breast-cancer-diagnosis-with-f1-score-99", "size": "9869", "language": "python", "html_url": "https://www.kaggle.com/code/busthon/breast-cancer-diagnosis-with-f1-score-99", "git_url": "https://www.kaggle.com/code/busthon/breast-cancer-diagnosis-with-f1-score-99"}