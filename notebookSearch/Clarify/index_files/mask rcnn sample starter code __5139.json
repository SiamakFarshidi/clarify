{"name": "mask rcnn sample starter code ", "full_name": " h3 First Install Kaggle API for download competition data h3 MD ai Annotator h3 Install Matterport s Mask RCNN model from github h3 Some setup functions and classes for Mask RCNN h3 Examine the annotation data parse the dataset and view dicom fields h3 Split the data into training and validation datasets h3 Create and prepare the training dataset using the DetectorDataset class h3 Let s look at a sample annotation We see a bounding box with x y of the the top left corner as well as the width and height h3 Display a random image with bounding boxes h3 Image Augmentation Try finetuning some variables to custom values h3 Now it s time to train the model Note that training even a basic model can take a few hours h3 How does the predicted box compared to the expected value Let s use the validation dataset to check h3 Final steps Create the submission file ", "stargazers_count": 0, "forks_count": 0, "description": " Mask RCNN Sample Starter Model for the RSNA Pneumonia Detection Challenge MD ai https www md ai The dataset for this challenge created on the MD ai platform in collaboration with the Radiological Society of North America RSNA the Society of Thoracic Radiology STR the US National Institutes of Health NIH and Kaggle This notebook covers the basics of parsing the competition dataset training using a detector basd on the Mask RCNN algorithm https arxiv org abs 1703 06870 for object detection and instance segmentation Note that the Mask RCNN detector configuration parameters have been selected to reduce training time for demonstration purposes they are not optimal This is based on our deep learning for medical imaging lessons Lesson 1 Classification of chest vs adominal X rays using TensorFlow Keras Github https github com mdai ml lessons blob master lesson1 xray images classification ipynb Annotator https public md ai annotator project PVq9raBJ Lesson 2 Lung X Rays Semantic Segmentation using UNets Github https github com mdai ml lessons blob master lesson2 lung xrays segmentation ipynb Annotator https public md ai annotator project aGq4k6NW workspace Lesson 3 RSNA Pneumonia detection using Kaggle data format Github https github com mdai ml lessons blob master lesson3 rsna pneumonia detection kaggle ipynb Annotator https public md ai annotator project LxR6zdR2 workspace Lesson 3 RSNA Pneumonia detection using MD ai python client library Github https github com mdai ml lessons blob master lesson3 rsna pneumonia detection mdai client lib ipynb Annotator https public md ai annotator project LxR6zdR2 workspace Copyright 2018 MD ai Inc Licensed under the Apache License Version 2 0 First Install Kaggle API for download competition data MD ai Annotator Additionally If you are interested in augmenting the existing annotations you can use the MD ai annotator to view DICOM images and create annotatios to be exported MD ai annotator project URL for the Kaggle dataset https public md ai annotator project LxR6zdR2 workspace Annotator features The annotator can be used to view DICOM images and create image and exam level annotations You can apply the annotator to filter by label adjudicate annotations and assign annotation tasks to your team Notebooks can be built directly within the annotator for rapid model development The data wrangling is abstracted away by the interface and by our MD ai library Simplifies image annotation in order to widen the participation in the futrue of medical image deep learning The annotator allows you to create initial annotations build and run models modify finetune the annotations based on predicted values and repeat The MD ai python client library implements functions to easily download images and annotations and to prepare the datasets used to train the model for classification See the following example notebook for parsing annotations and training using MD ai annotator https github com mdai ml lessons blob master lesson3 rsna pneumonia detection mdai client lib ipynb MD ai URL https www md ai MD ai documentation URL https docs md ai Install Matterport s Mask RCNN model from github See the Matterport s implementation of Mask RCNN https github com matterport Mask RCNN Some setup functions and classes for Mask RCNN dicom fps is a list of the dicom image path and filenames image annotions is a dictionary of the annotations keyed by the filenames parsing the dataset returns a list of the image filenames and the annotations dictionary Examine the annotation data parse the dataset and view dicom fields Split the data into training and validation datasets Note We have only used only a portion of the images for demonstration purposes See comments below To use all the images do image fps list list image fps Or change the number of images from 100 to a custom number Create and prepare the training dataset using the DetectorDataset class Let s look at a sample annotation We see a bounding box with x y of the the top left corner as well as the width and height Display a random image with bounding boxes Image Augmentation Try finetuning some variables to custom values Now it s time to train the model Note that training even a basic model can take a few hours Note the following model is for demonstration purpose only We have limited the training to one epoch and have set nominal values for the Detector Configuration to reduce run time dataset train and dataset val are derived from DetectorDataset DetectorDataset loads images from image filenames and masks from the annotation data model is Mask RCNN How does the predicted box compared to the expected value Let s use the validation dataset to check Note that we trained only one epoch for demonstration purposes ONLY You might be able to improve performance running more epochs Final steps Create the submission file  Directory to save logs and trained model python setup py q install Import Mask RCNN To find local version of the library The following parameters have been selected to reduce running time for demonstration purposes These are not optimal Give the configuration a recognizable name Train on 1 GPU and 8 images per GPU We can put multiple images on each GPU because the images are small Batch size is 8 GPUs images GPU background 1 pneumonia classes Add classes add images If grayscale Convert to RGB for consistency training dataset read dicom image from filepath get image array show dicom fields Original DICOM image size 1024 x 1024 Modify this line to use more or fewer images for training validation To use all images do image fps list list image fps split dataset into training vs validation dataset split ratio is set to 0 9 vs 0 1 train vs validation respectively prepare the training dataset Show annotation s for a DICOM image prepare the validation dataset Load and display random samples and their bounding boxes Suggestion Run this a few times to see different examples Image augmentation Train Mask RCNN Model select trained model Pick last directory Find the last checkpoint Recreate the model in inference mode Load trained weights fill in path to trained weights here set color for class Show few example of ground truth vs predictions on the validation dataset verbose 1 Get filenames of test dataset DICOM images Make predictions on test images write out sample submission assume square image If grayscale Convert to RGB for consistency x1 y1 width height bboxes str format x1 y1 width height predict only the first 50 entries cat submission csv show a few test image detection example original image assume square image If grayscale Convert to RGB for consistency remove files to allow committing hit files limit otherwise ", "id": "drt2290078/mask-rcnn-sample-starter-code", "size": "5139", "language": "python", "html_url": "https://www.kaggle.com/code/drt2290078/mask-rcnn-sample-starter-code", "git_url": "https://www.kaggle.com/code/drt2290078/mask-rcnn-sample-starter-code"}