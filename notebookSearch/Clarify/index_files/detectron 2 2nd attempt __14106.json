{"name": "detectron 2 2nd attempt ", "full_name": " h3 CHANGES h1 VinBigData detectron2 train h1 Table of Contents h1 Dataset preparation h1 Installation h1 Training method implementations h2 Data preparation h1 Customizing detectron2 trainer h2 Mapper for augmentation h2 Evaluator h2 Loss evaluation hook h2 LR scheduling h1 Loading Data h1 Data Visualization h1 Training h1 Visualize loss curve competition metric AP40 h1 Visualization of augmentation by Mapper h3 If this kernel helps you please upvote to keep me motivated Thanks h1 Next step h2 Discussions ", "stargazers_count": 0, "forks_count": 0, "description": " CHANGES 1 Image size to 1024 2 Iter from 10k to 12k VinBigData detectron2 train This competition is object detaction task to find a class and location of thoracic abnormalities from chest x ray image radiographs detectron2 is one of the famous pytorch object detection library I will introduce how to use this library to train models provided by this library with this competition s data https github com facebookresearch detectron2 Detectron2 is Facebook AI Research s next generation software system that implements state of the art object detection algorithms It is a ground up rewrite of the previous version Detectron and it originates from maskrcnn benchmark https user images githubusercontent com 1381301 66535560 d3422200 eace 11e9 9123 5535d469db19 png UPDATE 2021 1 11 I published prediction kernel please check https www kaggle com corochann vinbigdata detectron2 prediction too UPDATE 2021 1 24 I added more advanced usage to customize code detectron2 code especially How to define use mapper to add your customized augmentation Use validation data during training Define Evaluator and calculating competition metric AP40 Define Hook to calculate validation loss plotting training validation loss curve div style color red UPDATE 2021 2 18 Added links to relevant useful discussions in Next step topic div Table of Contents Dataset preparation dataset br Installation installation br Training method implementations train method br Customizing detectron2 trainer custom trainer Advanced topic skip it first time br Mapper for augmentation mapper br Evaluator evaluator br Loss evaluation hook loss hook br Loading Data load data br Data Visualization data vis br Training training br Visualize loss curve competition metric AP40 vis loss br Visualization of augmentation by Mapper vis aug br Next step next step br a id dataset a Dataset preparation Preprocessing x ray image format dicom into normal png image format is already done by xhlulu in the below discussion Multiple preprocessed datasets 256 512 1024px PNG and JPG modified and original ratio https www kaggle com c vinbigdata chest xray abnormalities detection discussion 207955 Here I will just use the dataset VinBigData Chest X ray Resized PNG 256x256 https www kaggle com xhlulu vinbigdata chest xray resized png 256x256 to skip the preprocessing and focus on modeling part I also uploaded the original sized png images vinbigdata chest xray original png https www kaggle com corochann vinbigdata chest xray original png notebook https www kaggle com corochann preprocessing image original size lossless png on kaggle fails due to disk limit Please upvote the dataset as well a id installation a Installation detectron2 is not pre installed in this kaggle docker so let s install it We can follow installation instruction https github com facebookresearch detectron2 blob master INSTALL md we need to know CUDA and pytorch version to install correct detectron2 It seems CUDA 10 2 and torch 1 7 0 is used in this kaggle docker image See installation https detectron2 readthedocs io tutorials install html for details a id train method a Training method implementations Basically we don t need to implement neural network part detectron2 already implements famous architectures and provides its pre trained weights We can finetune these pre trained architectures These models are summarized in MODEL ZOO md https github com facebookresearch detectron2 blob master MODEL ZOO md In this competition we need object detection model I will choose R50 FPN https github com facebookresearch detectron2 blob master configs COCO Detection faster rcnn R 50 FPN 3x yaml for this kernel Data preparation detectron2 provides high level API for training custom dataset To define custom dataset we need to create list of dict dataset dicts where each dict contains following file name file name of the image image id id of the image index is used here height height of the image width width of the image annotation This is the ground truth annotation data for object detection which contains following bbox bounding box pixel location with shape n boxes 4 bbox mode BoxMode XYXY ABS is used here meaning that absolute value of xmin ymin xmax ymax annotation is used in the bbox category id class label id for each bounding box with shape n boxes get vinbigdata dicts is for train dataset preparation and get vinbigdata dicts test is for test dataset preparation This dataset dicts contains the metadata for actual data fed into the neural network br It is loaded beforehand of the training on memory so it should contain all the metadata image filepath etc to construct training dataset but should not contain heavy data br In practice loading all the taining image arrays are too heavy to be loaded on memory so these are loaded inside DataLoader on demand This is done by mapper class in detectron2 as I will expain later a id custom trainer a Customizing detectron2 trainer This section is advanced I recommend to jump to Training scripts section for the first time of reading You can refer the Detectron2 Beginner s Tutorial https colab research google com drive 16jcaJoc6bCFAQ96jDe2HwtXj7BMD m5 scrollTo QHnVupBBn9eR Colab Notebook or version 7 of this kernel https www kaggle com corochann vinbigdata detectron2 train scriptVersionId 51628272 for the simple usage of detectron2 how to train custom dataset DefaultTrainer is used in the example which provides the starting point to train your model with custom dataset It is nice to start with however I want to customize the training behavior more to improve the model s performance We can make own Trainer class MyTrainer here for this purpose and override methods to provide customized behavior a id mapper a Mapper for augmentation Mapper class is used inside pytorch DataLoader It is responsible for converting dataset dicts into actual data fed into the neural network and we can insert augmentation process in this Mapper class Ref detectron2 docs Dataloader https detectron2 readthedocs io en latest tutorials data loading html I implemented MyMapper which uses augmentations implemented in detectron2 and AlbumentationsMapper which uses albumentations library augmentations br I will demonstrate these augmentations later so you can skip reading the code and please just jump to next a id evaluator a Evaluator To evaluate validation dataset to calculate competition metric we need Evaluator Famouns dataset s evaluator is already implemented in detectron2 br For example many kinds of AP Average Precision is calculted in COCOEvaluator br COCOEvaluator only calculates AP with IoU from 0 50 to 0 95 but we need AP with IoU 0 40 Here I modified COCOEvaluator implementation to calculate AP with IoU 0 40 and replaced to show this value instead of AP with IoU 0 70 a id loss hook a Loss evaluation hook We implemented Evaluator and now we can calculate competition metric however validation loss is not calculated inside Evaluator This is because model s evaluation is done in model eval mode and it outputs bounding box prediction but does not output loss To calculate validation loss we need to call model with the training mode This can be done by adding Hook which calculates the loss to the trainer br Trainer has attribute storage and calculated metrics are summarized Its content is saved to metric json jsonl format during training Below LossEvalHook calculates validation loss in do loss eval method and self trainer storage put scalars validation loss mean loss is called to put this validation loss to the storage which will be saved to metrics json br Note that current implementation is not efficient in the sense that Evaluator s evaluation and LossEvalHook s loss calculation run separately even if both need a model forward calculation for same validation data Ref Training on Detectron2 with a Validation set and plot loss on it to avoid overfitting https medium com apofeniaco training on detectron2 with a validation set and plot loss on it to avoid overfitting 6449418fbf4e Now all the preparation has done MyTrainer overwraps build evaluator method of DefaultTrainer provided by detectron2 to support validation dataset evaluation 1 build train loader build test loader These class methods deine how to construct DataLoader for training data validation data respectively Here AlbumentationMapper is passed to construct DataLoader to insert customized augmentation process 2 build evaluator This class method defines how to construct Evaluator Here implemented VinbigdataEvaluator is constructed we can also use COCOEvaluator here 3 build hooks This method defines how to construct hooks I insert LossEvalHook before evalutor to work well LR scheduling To further customize learning rate scheduling you may override build lr scheduler class method to construct any pytorch LRScheduler Default build lr schduler method docs https detectron2 readthedocs io en latest modules detectron2 solver build html build lr scheduler supports only 2 types of LR scheduling WarmupMultiStepLR default WarmupCosineLR You can change which one to use by setting cfg SOLVER LR SCHEDULER NAME as you can see from the docs Now the methods are ready main scripts starts from here a id load data a Loading Data This Flags class is to manage experiments I will tune these parameters through the competition to improve model s performance a id data vis a Data Visualization It s also very easy to visualize prepared training dataset with detectron2 br It provides Visualizer class we can use it to draw an image with bounding box as following a id training a Training It s actually very easy to use multiple gpus for training You just need to wrap above training scripts by main method and use launch method provided by detectron2 Please refer official example train net py https github com facebookresearch detectron2 blob master tools train net py L161 for details a id vis loss a Visualize loss curve competition metric AP40 As I explained the calculated metrics are saved in metrics json We can analyze plot them to check how the training proceeded Our Evaluator calculaes AP by class and it is easy to check which class is diffucult to train In my experiment Calcification seems to be the most difficult class to predict a id vis aug a Visualization of augmentation by Mapper Let s check the behavior of Mapper method Since mapper is used inside DataLoader we can check its behavior by constucting DataLoader and visualize the data processed by the DataLoader The defined Trainer class has class method build train loader We can construct train loader purely from cfg without instantiating trainer since it s class method Below code is to visualize the same data 4 times You can check that augmentation is applied and every time the image looks different Note that both detectron2 data transforms albumentations augmentations properly handles bounding box Thus bounding box is adjusted when the image is scaled rotated etc At first I was using detectron2 data transforms with MyMapper class it provides basic augmentations br Then I noticed that we can use many augmentations in albumentations so I implemented AlbumentationsMapper to support it br How many augmentations can be used in albumentations br You can see official github page all Pixel level transforms https github com albumentations team albumentations pixel level transforms and Spatial level transforms https github com albumentations team albumentations spatial level transforms with BBoxes checked can be used There are really many That s all I found that the competition data is not so many 15000 for all images 4000 images after filtering No finding images br It does not take long time to train less than a day so this competition may be a good choice for beginners who want to learn object detection h3 style color red If this kernel helps you please upvote to keep me motivated br Thanks h3 a id next step a Next step VinBigData detectron2 prediction https www kaggle com corochann vinbigdata detectron2 prediction kernel explains how to use trained model for the prediction and submisssion for this competition VinBigData 2 class classifier complete pipeline https www kaggle com corochann vinbigdata 2 class classifier complete pipeline kernel explains how to train 2 class classifier model for the prediction and submisssion for this competition Discussions These discussions are useful to further utilize this training notebook to conduct deeper experiment 1 step training prediction https www kaggle com c vinbigdata chest xray abnormalities detection discussion 219672 The 1 step pipeline which does not use any 2 class classifier approach is proposed What anchor size aspect ratio should be used https www kaggle com c vinbigdata chest xray abnormalities detection discussion 220295 Suggests how to predict more smaller sized high aspect ratio bonding boxes It affects to the score a lot Preferable radiologist s id in the test dataset https www kaggle com c vinbigdata chest xray abnormalities detection discussion 219221 Investigation of test dataset annotation distribution  plotly models setup For debug Load 1 image to get image size print row print row class name class name row class name It is No finding Use this No finding class with the bbox covering all image area This annotator does not find anything skip bbox original int row x min int row y min int row x max int row y max test meta pd read csv imgdir test meta csv For debug Load 1 image to get image size record image id index objs record annotations objs utils configs T Resize 800 800 it will be modified by code below if not self is train dataset dict pop annotations None dataset dict pop sem seg file name None return dataset dict h w it will be modified by code below aug input T AugInput image transforms self augmentations aug input image aug input image category id np array obj category id for obj in dataset dict annotations dtype np int64 Remove unnecessary field if not self is train dataset dict pop annotations None dataset dict pop sem seg file name None return dataset dict h w Copyright c Facebook Inc and its affiliates dimension of precision TxRxKxAxM IoU dimension of recall TxKxAxM stats 2 summarize 1 iouThr 75 maxDets self params maxDets 2 Infering it from predictions should be better Test set json files do not contain annotations evaluation must be performed using the COCO evaluation server Copy so the caller can do whatever with results unmap the category ids for COCO cocoapi does not handle empty results very well Saving generated box proposals to file Predicted box proposals are in XYXY ABS mode the standard metrics Compute per category AP from https github com facebookresearch Detectron blob a6a835f5b8208c45d0dce217ce9bbda915f44df7 detectron datasets json dataset evaluator py L222 L252 noqa precision has dims iou recall cls area range max dets area range index 0 all area ranges max dets index 1 typically 100 per image tabulate it use RLE to encode the masks because they are too large and takes memory since this evaluator stores outputs of the entire dataset counts is an array encoded by mask util as a byte stream Python3 s json writer which always produces strings cannot serialize a bytestream unless you decode it Thankfully utf 8 works out which is also what the pycocotools mask pyx does In COCO annotations keypoints coordinates are pixel indices However our predictions are floating point coordinates Therefore we subtract 0 5 to be consistent with the annotation format This is the inverse of data loading logic in datasets coco py inspired from Detectron https github com facebookresearch Detectron blob a6a835f5b8208c45d0dce217ce9bbda915f44df7 detectron datasets json dataset evaluator py L255 noqa Record max overlap value for each gt box Return vector of overlap values all small medium large 96 128 128 256 256 512 512 inf sort predictions in descending order TODO maybe remove this and make it explicit in the documentation guard against no boxes find which proposal box maximally covers each gt box and get the iou amount of coverage for each gt box find which gt box is best covered i e best most iou find the proposal box that covers the best covered gt box record the iou coverage of this gt box mark the proposal box and the gt box as used append recorded iou coverage level thresholds torch arange 0 5 0 95 1e 5 step dtype torch float32 compute recall for each iou threshold ar 2 np trapz recalls thresholds When evaluating mask AP if the results contain bbox cocoapi will use the box area as the area of the instance instead of the mask area This leads to a different definition of small medium large We remove the bbox field to let mask AP use mask area HACKING overwrite iouThrs to calc ious 0 4 Use the COCO default keypoint OKS sigmas unless overrides are specified COCOAPI requires every detection and every gt to have keypoints so we just take the first entry from both Copying inference on dataset from evaluator py self trainer storage put scalar validation loss mean loss return losses How loss is calculated on train loop self trainer storage put scalars timetest 11 from detectron2 evaluation import COCOEvaluator PascalVOCDetectionEvaluator return PascalVOCDetectionEvaluator dataset name not working return COCOEvaluator dataset name bbox False output dir output folder flags General Data config all train or valid20 original or wbf Training config images per batch this corresponds to total batch size WarmupMultiStepLR default or WarmupCosineLR Overwrite by param dict flags dict debug True outdir results debug imgdir name vinbigdata chest xray resized png 256x256 split mode valid20 iter 100 debug small value should be set roi batch size per image 128 faster and good enough for this toy dataset default 512 eval period 20 aug kwargs HorizontalFlip p 0 5 ShiftScaleRotate scale limit 0 15 rotate limit 10 p 0 5 RandomBrightnessContrast p 0 5 args parse Read data Read in the data CSV files alias sample submission pd read csv datadir sample submission csv To get number of data Visualize data print anom ind cv2 imshow out get image 1 pass aug kwargs to cfg Let training initialize from model zoo pick a good LR Small value Frequent save need a lot of storage NOTE this config means the number of classes but a few popular unofficial tutorials incorrect uses num classes 1 here 1 Loss curve ax set ylim 0 0 5 Visualize data import matplotlib pyplot as plt Ref https github com facebookresearch detectron2 blob 22b70a8078eb09da38d0fefa130d0f537562bebc tools visualize data py L79 L88 For visualization out visualizer draw dataset dict per image ", "id": "explorerboi/detectron-2-2nd-attempt", "size": "14106", "language": "python", "html_url": "https://www.kaggle.com/code/explorerboi/detectron-2-2nd-attempt", "git_url": "https://www.kaggle.com/code/explorerboi/detectron-2-2nd-attempt"}