{"name": "osic data preprocessing for cnn ml starter ", "full_name": " h1 Resampling h1 3D Plotting h1 Normalization h1 Zero centering ", "stargazers_count": 0, "forks_count": 0, "description": "ACKNOWLEDGEMENT https www kaggle com gzuidhof full preprocessing tutorial https www raddq com dicom processing segmentation visualization in python In this notebook we learn Loading DICOM data using pydicom Used 1D histogram 2D and 3D plots to display DICOM images Pre processed data for future machine learning projects Conversion of pixel value to Hundsfeld units Resampling for isotropy normalization zero centering Loading the files Dicom is the de facto file standard in medical imaging These files contain a lot of metadata such as the pixel size so how long one pixel is in every dimension in the real world This pixel size coarseness of the scan differs from scan to scan e g the distance between slices may differ which can hurt performance of CNN approaches We can deal with this by isomorphic resampling which we will do later Slice Thickness is a parameter that can be selected by the technologist This will change the thickness of our slice in millimeters By increasing the slice thickness many more different types of tissues will be collected in our 2D slice This can cause blurring in our image also known as partial voluming Picture Coverage By increasing the slice thickness we will increase our coverage 1 jpg attachment 1 jpg The unit of measurement in CT scans is the Hounsfield Unit HU which is a measure of radiodensity CT scanners are carefully calibrated to accurately measure this From Wikipedia 4rlyReh png attachment 4rlyReh png By default however the returned values are not in this unit Let s fix this Some scanners have cylindrical scanning bounds but the output image is square The pixels that fall outside of these bounds get the fixed value 2000 The first step is setting these values to 0 which currently corresponds to air Next let s go back to HU units by multiplying with the rescale slope and adding the intercept which are conveniently stored in the metadata of the scans Resampling A scan may have a pixel spacing of 2 5 0 5 0 5 which means that the distance between slices is 2 5 millimeters For a different scan this may be 1 5 0 725 0 725 this can be problematic for automatic analysis e g using ConvNets A common method of dealing with this is resampling the full dataset to a certain isotropic resolution If we choose to resample everything to 1mm1mm1mm pixels we can use 3D convnets without worrying about learning zoom slice thickness invariance Whilst this may seem like a very simple step it has quite some edge cases due to rounding Also it takes quite a while Below code worked well for us and deals with the edge cases Although we have each individual slices it is not immediately clear how thick each slice is Slice Thickness 10 000000 Pixel Spacing row col 0 652344 0 652344 This means we have 10 00 mm slices and each voxel represents 0 652344 mm Because a CT slice is typically reconstructed at 512 x 512 voxels each slice represents approximately 370 mm of data in length and width Using the metadata from the DICOM we can figure out the size of each voxel as the slice thickness In order to display the CT in 3D isometric form which we will do below and also to compare between different scans it would be useful to ensure that each slice is resampled in 1x1x1 mm pixels and slices 3D Plotting Normalization Our values currently range from 1024 to around 2000 Anything above 400 is not interesting to us as these are simply bones with different radiodensity A commonly used set of thresholds in the LUNA16 competition to normalize between are 1000 and 400 Here s some code you can use Zero centering As a final preprocessing step it is advisory to zero center your data so that your mean value is 0 To do this you simply subtract the mean pixel value from all pixels To determine this mean you simply average all images in the whole dataset If that sounds like a lot of work we found this to be around 0 25 in the LUNA16 competition Warning Do not zero center with the mean per image like is done in some kernels on here The CT scanners are calibrated to return accurate HU measurements There is no such thing as an image with lower contrast or brightness like in normal pictures With these steps your images are ready for consumption by your CNN or other ML method  linear algebra data processing CSV file I O e g pd read csv lets read metadeta of pydiacom file order the slice serially lets create a function for above task Convert to int16 from sometimes int16 should be possible as values should always be low enough 32k Set outside of scan pixels to 0 The intercept is usually 1024 so air is approximately 0 Convert to Hounsfield units HU lets take alook at patient Determine current pixel spacing Position the scan upright so the head of the patient would be at the top facing the camera get image in order h w c Fancy indexing verts faces to generate a collection of triangles ", "id": "saurah403/osic-data-preprocessing-for-cnn-ml-starter", "size": "4394", "language": "python", "html_url": "https://www.kaggle.com/code/saurah403/osic-data-preprocessing-for-cnn-ml-starter", "git_url": "https://www.kaggle.com/code/saurah403/osic-data-preprocessing-for-cnn-ml-starter"}