{"name": "densenet169 with wsi split and focalloss ", "full_name": " h1 Count per WSI id h2 Take only Ids of which we know the WSI h2 extract all images we dont know the WSI id of will go into validation set h2 Get 20 of the WSIs as validation set maybe later make sure its stratified h2 get the integer index for all the images with WSIs of the validation set h3 Warm up with frozen weight is done on a subset so we dont have to waste an entire epoch h3 Predit the validation data using TTA h3 Now predict on test set h3 prepare submission h2 I add the score to the name of the file so I can later plot the leaderboard score versus my validation score ", "stargazers_count": 0, "forks_count": 0, "description": "This is a Fork of my Densenet169 https www kaggle com guntherthepenguin fastai v1 densenet169 kernel The only thing new is I included the WSI ids https www kaggle com tywangty histopathologiccancerwsi from this discussion https www kaggle com c histopathologic cancer detection discussion 83760 to reduce overfitting and correlations between validation and training set Thanks to SM https www kaggle com sermakarevich for the WSI set and Idea and Taylor https www kaggle com tywangty for uploading it on kaggle Defining a metric so after epoch I get the validation ROC AUC score In Case I want to run quick tests use a subsample Count per WSI id Take only Ids of which we know the WSI extract all images we dont know the WSI id of will go into validation set Get 20 of the WSIs as validation set maybe later make sure its stratified get the integer index for all the images with WSIs of the validation set Warm up with frozen weight is done on a subset so we dont have to waste an entire epoch Predit the validation data using TTA Here for every image we want to predict on n augs images are augmented form the original image We can then compare the predictions on for example the image and the image flipped roated slightly different crop lighting stretched etc For now only the diherdral and rotations are used THis gives a nice extra percent or two when compared to the auc above after training where not TTA is used I also test if mean or max is better to use on the image and its augments but it can t conclude anything yet Now predict on test set prepare submission I now load in the sample submission and put my predictions in the label column and save to a new file Sometimes its important in which order the ids in the submissions are so to make sure I don t mess up I put them in the same order My first submission had a 50 score so I somewhere messed up the order oder the matching of id to label since fname clean is the id we can just use that as index when adding the correct label in our dataframe I add the score to the name of the file so I can later plot the leaderboard score versus my validation score In the fastai course Jeremy mentions that if you have a monotonic relation between validation and LB score the way you set up your validation set matches what the test set consists of  Apprently 2 cpus per kaggle node so 4 threads I think ", "id": "guntherthepenguin/densenet169-with-wsi-split-and-focalloss", "size": "2380", "language": "python", "html_url": "https://www.kaggle.com/code/guntherthepenguin/densenet169-with-wsi-split-and-focalloss", "git_url": "https://www.kaggle.com/code/guntherthepenguin/densenet169-with-wsi-split-and-focalloss"}