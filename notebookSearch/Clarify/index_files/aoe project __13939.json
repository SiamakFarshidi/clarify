{"name": "aoe project ", "full_name": " h1 Art of Engineering BME Departmental Project h2 Goals h2 Dataset h2 Sections h2 Grading of 100 points h1 Section 1 General functions h3 Checklist h1 Section 2 Simple U Net h1 Section 3 Residual Attention U Net Your part h1 Section 4 Report and submission h3 Submission Checklist h3 Deadline ", "stargazers_count": 0, "forks_count": 0, "description": " Art of Engineering BME Departmental Project Goals 1 Learn how to work with large image datasets 2 Learn how to implement a simple U Net 3 Learn how to train and test a U Net 3 Implement a Residual Attention U Net https arxiv org abs 2001 05548 to segment single cells using fluorescence widefield microscopy images 4 Present the statistical analysis and model s performance Dataset The dataset consists of three folders named train valid and test that is for training validation and testing the model Each folder has two folders image containing RGB fluorescence widefield microscopy images as inputs and mask which contains segmentation masks as targets RGB images are named by integer numbers for trainset image 0001 to image 4140 for validation set image 0001 to image 1380 and for test set image 0001 to image 2070 Similarly the segmentation masks are mask 0001 to mask x where x depends on the number of samples in the set Both RGB and segmentation masks are in png format with the size of 512 times512 pixels span style color red fontsize 18px How to add the Dataset span 1 On right side panel click on Add Data 2 From opened window click on Search by URL 3 Search for https www kaggle com soroush361 singlecellsegmentation 4 Click on Add button Sections 1 General functions for making dataset of train validation and test sets train the model save its weights plotting the learning curve and test the model on the test set and present the statistical results 2 An implementation of simple U Net https arxiv org abs 1505 04597 and its results as an example 3 Your implementation of Residual Attention U Net https arxiv org abs 2001 05548 and results 4 Report and submission span style color red font size 22px font Warnings span 1 Please don t share the dataset with anyone else other than students in the class 2 Please don t copy other teams code Don t forget that your worst try is always better than cheating 3 Comment on your codes properly 4 Please choose meaningful names for your variables 4 Proper citing is a must if you are using other papers or codes publicly available Consider this both in the implementations and final report 5 Take advantage of Markdown blocks to explain what you are trying to do in the next code block Grading of 100 points 1 Successful implementation 35 points 2 Successful results 35 points 3 Report 30 points 4 Innovative approaches i e changing loss function new preprocessing pipeline edge enhancment etc Extra 20 points Section 1 General functions In this section we implemented few functions to make reading the dataset training validating and saving the model testing and generating the results and presenting the statistical analysis easy for you Please read the functions and make sure you understand each line of them If you have any questions reach to CAs via email Soroush sa3617 columbia edu Hengda hh2699 columbia edu or ask your questions during lecture office hours Acknowledgment Most of the following implementations are a modified version of this repository https github com milesial Pytorch UNet Please cite their work if you would use these functions in the future Checklist Make sure the session is started Make sure internet access is granted Make sure the GPU accelerator is selected Make sure that you ve added the dataset Data Add data Search by URL search https www kaggle com soroush361 singlecellsegmentation Add First we need to import all the packages we will need during the implementations In the First Tutorial you had seen that we uploaded the whole MNIST dataset into Python variables and then we trained our model using those variables However the MNIST dataset is relatively small and it was possible to do so The SingleCellSegmentation is larger than the MNIST and we need to read each image batch at a time and train validate test our model and then move to the next image batch To do so we need a BasicDataset instance that reads an image and respective segmentation mask In below we implemented the BasicDataset class that does the job Furthermore you can implement any kinds of preprocessing you wish to do in this implementation For example in this class we resized the resolutions to 256 times256 pixels to speed up the training process and reduce memory consumption In addition we scaled the intensities from 0 255 to 0 1 This document will use Pytorch and Pytroch s inputs shape format is Channels Width Height rather than Width Height Channels we changed the image axis as well Before moving on let s look into the number of samples we have for the train validate and test our models Also let s check if our BasicDataset implementation works by pulling out a random sample of the training set Don t forget that we need to reverse some of the preprocessing steps In the lectures we discussed some segmentation metrics In this project we are more interested in DICE score https en wikipedia org wiki S C3 B8rensen E2 80 93Dice coefficient metric Therefore we have implemented a function that computes multi class DICE scores in general which works in our binary segmentation https miro medium com max 858 1 yUd5ckecHjWZf6hGrdlwzA png The DICE score shows how successfully our model could predict correct labels in the right location Its score varies from 0 0 for no overlap and 1 0 for perfect overlap Our next function is train net This function is essentially our training core This function will take the model net the number of epochs we would like to train our model epochs batch size batch size and learning rate lr This function will create a directory in kaggle working directory with the model name to save model weight at the end of each epoch as well as a training summary that contains training validation losses and dice scores in a json file model name model name TrainingSummary json In addition all further plots will also be saved in this directory In this function we automatically create an instance of the training set and validation set using our previously defined BasicDataset Then it will make data loaders for those datasets with the batch size that has been given It trains the model for the given number of epochs and updates the weights and learning rate schedular In this function the loss function will be selected based on the segmentation type Multi class or Binary However in both scenarios it will be Cross Entropy If you wish to change your loss function or learning rate scheduler you need to modify this function Read this function thoroughly and make sure you understand most of it After training the model we are usually interested in looking at the learning curve Similar to what you had seen in the First Tutorial The plot learning curve function will take a previously trained model net and looks for its summary then loads it and plot the losses and dices after each epoch for both training and validation sets Now that the model is appropriately trained by looking at the training curve we need to test it on the test set to ensure that our trained model works on unseen data The test net function will load the weights of the Best Model that obtains the maximum dice score on the validation set If you wish to load the weights of a specific epoch you may set the epoch argument when you call this function then creates an instance of the BasicDataset using test set and predicts the segmentation masks on the test images Additionally this function will save the predicted masks in model name pred mask directory with a file format of pred mask x png where the x is the input index Finally this function will print average and standard deviation on loss values and dice scores on the test set This function will also save dice score and loss value for each individual input in a json format model name model name TestResults json for further visualization If you changed the loss function during training you need also change it in this function to generate comparable results According to the test set s dice scores the plot best worst samples function is designed to display five of the best and worst segmentation masks This function will take the model to search for its TestResults json file The final general function is statistical report that takes the model net and look for all the predicted masks for the test set and compares it with the True masks to print the Sensitivity Recall Precision F1 score https en wikipedia org wiki Sensitivity and specificity and average accuracy https en wikipedia org wiki Sensitivity and specificity Furthermore this function will display the confusion matrix for the test set Here is a function that displays the weights of the first convolution layer of the Simple U Net called plot weights UNet Unfortunately because it is almost impossible to make a function that visualizes the weights of all possible models this function will only work for our Simple U Net example Use this as an example to understand how you can create your own version of this function as it is requested to visualize your implementation s weights Section 2 Simple U Net This section will implement a simple U Net then train and validate it on the given dataset We will utilize previously defined functions to test our best U net model on the test set and show its performance by reporting the statistical measures https camo githubusercontent com 41ded1456b9dbe13b8d73d8da539dac95cb8aa721ebe5fb798af732ca9f04c92 68747470733a2f2f692e696d6775722e636f6d2f6a6544567071462e706e67 To implement the U Net we first define four blocks that we will use multiple times while designing the complete architecture DoubleCov is block that contains these layers Conv2d BatchNormalization ReLU Conv2d BatchNormalization ReLU Down is a downsampling block which contains Maxpooling and DoubleConv after Maxpooling Decoding layers Up is an upsampling block that upsamples the input then pass it through a DoubleConv Encoding Layers OutConv is just a 1 times1 2D convolution that serves as an output layer in our U Net model Now we build our U Net using the blocks we defined above span style color red font size 18px font Important span In order to use previously defined functions we need to have a name and n classes property for our model Till Now we only defined our architecture here we need to make an instance of it and set its initial arguments Then we will print architecture Time to train our U Net using the train net function for 10 epochs When the training is finished we may plot the training curve of our simple U Net using plot learning curve function Let s test our trained U Net on the test set using test net function Now that the test set predicted mask is saved we may show top five best and works cases in the test set usine plot best worst samples function Besides the few samples visualization which serves as a qualitative assessment we need to present some quantitative statistical analysis using the statistical report function This function will take some time to finish its job The final step would be investigating visualizing the weights of our trained Simple U Net Here we only visualize the first layer s weights using plot weights UNet function Section 3 Residual Attention U Net Your part In this section you are required to read Segmentation with Residual Attention U Net and an Edge Enhancement Approach Preserves Cell Shape Features https arxiv org abs 2001 05548 paper and implement their proposed architecture Then produce the predicted masks for the test set and analyze the performance of your implementation Feel free to use general functions defined in Section 1 or write your version of the training validation testing procedure Use the Section 2 Simple U Net implementation as an example for your implementation span style color red font size 18px font Important span You are absolutely welcomed to use the paper s GitHub repository https github com SAIL GuoLab Cell Segmentation and Tracking to get help for your implementation Furthermore if you wish to use other resources other than other students code please cite their work properly The following code blocks are just a draft for you to have some hints about what you need to do Free free to add remove edit or re write any part of it Section 4 Report and submission Please write a short report about your implementation and analyze your result in an IEEE conference paper template https www ieee org conferences publishing templates html and then submit the PDF version of it via CourseWorks https courseworks2 columbia edu along with your copy of this Notebook in ipynb format The report must include these sections 1 Introduction 2 Dataset description 2 Method 3 Results 4 Discussion and Conclusion If you want to include the figures you have made in this Notebook you need to save them in the working directory Then you need to download them Click on the dots on right side of eachh file and Download If you are using the general function they are saved in the model s directory in Kaggle working model name model name figure name png pattern Submission Checklist Make sure you ve written your name s Make sure you save your Notebook correctly and it contains your notes codes and figures span style color red fontsize 28px Deadline span December 17 2020 11 59 pm EST  Write yours and your teammates name s and UNI s like Joonsoo Lee jl5062 in here This function takes folder name train valid test as input and creates an instance of BasicDataset according to that fodler This function returns the lenght of the dataset AKA number of samples in that set This function takes an index i which is between 0 to len BasicDataset The return of the previous function then returns RGB image mask Binary and the index of the file name Which we will use for visualization The preprocessing step is also implemented in this function Convert BGR to RGB Resize all images from 512 to 256 H and W Scale between 0 to 1 Make sure that the mask are binary 0 or 1 HWC to CHW Create train validation and test dataset instances Make sure that the masks shapes are Batch 1 W H Make a variable to report the dices per each sample in the bacth Loop over samples in the batch Binary segmentation Automatically the background will be disregarded Multi class segmentation Skip 0 index as background Pick up all the pixels in both Ground Truth and estimated mask that has been assigned as class j Then make a binary map to be passed to dice coeff binary function Skip if there are no pixel assigned to class j neither on estimate nor on true mask This happens when there is no classes presented in the sample and everything is predicted as background Thus DICE is 1 The out put would be a numpy array with shape Batch that contains Dice score for each sample in the batch img cv2 imread input singlecellsegmentation SingleCellSegmentation valid image image 0001 png def my loss ground pred LoG nd gaussian laplace ground 1 a cv2 threshold src LoG thresh 0 001 type cv2 THRESH BINARY maxval 1 b cv2 threshold src LoG thresh 0 002 type cv2 THRESH BINARY INV maxval 1 Was trying to work on the edge detection algorithm described but I wasn t sure how to vectorize the outer and inner edge Check if GPU is available Change the optimizer and learning rate scheduler if these don t suits your model This function is a general mode for multi class U Net however we only have one class Therefore only BCEWithLogitsLoss will be used If you wish to use a different Loss function change criterion to what desires your model A quick reminder the input of both Loss functions CrossEntropyLoss and BCEWithLogitsLoss doesn t need to be normalized softmax is internally implemented in loss Load a batch and pass it to the device CPU or GPU Produce the estimated mask using current weights Compute the loss We need to multiply by batch size since the batch loss is the average of the loss over all samples in the batch If it s a ulti class segmentation the predicted mask would be made by passing the network output through a softmax convert it to probabliti between 0 and 1 then take the maximum value index over the channel axis as the final label In case of binary segmentation we need to pass values one channel output of the network through the Sigmoid function values between 0 and 1 then threshold it by 0 5 it can be changed You can change the probablity threshold Loop over the dice scores of all the samples in the batch Reset gradient values Compute the backward losses Clip gradient to avoid sudden changes Update weights This part is almost the same as training with the difference that we will set all layers to evaluation mode effects some layers such as BN and Dropout and also we don t need to calculate the gradient since we are only evaluating current state of the model This will speed up the process and cause it to consume less memory You can change the probablity threshold We choose our best model based on validation dice score Now update our learning rate scheduler based on the average dice score over all validation samples Save this state as the best model if it is Training summary will be saved as a json file for further visualization plt text Create directory to save test masks Check if GPU is available Don t forget to change the criterion if you are using different loss function during training There is only one id in img id since the batch size is one You can change the probablity threshold Since the batch size is 1 you don t need to loop over the samples in the batch Save predicted mask First we need to remove batch and channel axis Knowing the batch size is one during test and then convert it to numpy After that we need to convert the dynamic range from 0 1 to 0 255 to save the predicted mask Now we use openCV to save our predicted mask with the name of the original image index Save testset dice score and loss value per each sample in a json file Sort based on dice scores print test resuls items Don t forgt to resize the images like what we did in the Dataset implementation BGR to RGB Turn off gradients Search in all layers in the network However only the first convolution layer will be shown Check if that layer m is an instance of nn Conv2d Convert weights to numpy array assumtion that number of filters are n 2 Get filters weidth and hights Compute sqrt of total filters to plot first nxn filters only Visualization reasons Take minimum and maximum values to display filters weights in a compareable way idx is just a counter Dont forget to convert CHW to HWC leave the function early if bilinear use the normal convolutions to reduce the number of channels input is CHW if you have padding issues see https github com HaiyongJiang U Net Pytorch Unstructured Buggy commit 0e854509c2cea854e247a9c615f175f76fbb2e3a https github com xiaopeng liao Pytorch UNet commit 8ebac70e633bac59fc22bb5195e513d5832fb3bd Input has three channels and we have one class to be segmented cell In fact we have two classes cells and background but with a probability between 0 to 1 we may seperate those For multi class segmentation make sure you account for background 0 index as well For example if you have two classes cat and dog you must account for background too therefore n classes 3 0 Background 1 Cat 2 Dog 2d convolution then batch normalization then ReLU then 2d convolution again then batch normilization again then ReLU Then we add this sample to the original sample given to the function and output it Does not maxpool different than previously definied down block for regular UNet Upscale then convolution batch normalization ReLU F g F l in the application g1 x1 ends up highlighting the convolution even more Attention block is only used when upscaling encoding path Maxpool is done in it s own function decoding concat path Train your model for as many epochs as you like be careful that the training should finish within the 9 hour session limitation you have Plot learning curve Test your model Display few samples of the results Print the statistical analysis Plot your model s weights Visualization ", "id": "joonsoolee/aoe-project", "size": "13939", "language": "python", "html_url": "https://www.kaggle.com/code/joonsoolee/aoe-project", "git_url": "https://www.kaggle.com/code/joonsoolee/aoe-project"}